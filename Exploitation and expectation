import numpy as np
import matplotlib.pyplot as plt

# Define a simple 1D bandit problem
class Bandit:
    def __init__(self, true_mean, initial_estimate):
        self.true_mean = true_mean
        self.estimated_mean = initial_estimate
        self.num_pulls = 0

    def pull(self):
        return np.random.normal(self.true_mean, 1)

    def update_estimate(self, reward):
        self.num_pulls += 1
        self.estimated_mean = (1/self.num_pulls) * ((self.num_pulls - 1) * self.estimated_mean + reward)

# Define an epsilon-greedy agent
class EpsilonGreedyAgent:
    def __init__(self, epsilon):
        self.epsilon = epsilon

    def select_action(self, bandits):
        if np.random.rand() < self.epsilon:
            return np.random.choice(len(bandits))  # Exploration
        else:
            return np.argmax([bandit.estimated_mean for bandit in bandits])  # Exploitation

# Define parameters
num_bandits = 10
true_means = np.random.normal(0, 1, num_bandits)
initial_estimate = 0
num_episodes = 1000
num_steps = 1000
epsilon_values = [0.1, 0.01]

# Run experiments for each epsilon value
for epsilon in epsilon_values:
    total_rewards = np.zeros(num_steps)
    for episode in range(num_episodes):
        bandits = [Bandit(true_mean, initial_estimate) for true_mean in true_means]
        agent = EpsilonGreedyAgent(epsilon)
        episode_rewards = []
        for step in range(num_steps):
            action = agent.select_action(bandits)
            reward = bandits[action].pull()
            bandits[action].update_estimate(reward)
            episode_rewards.append(reward)
        total_rewards += np.cumsum(episode_rewards) / num_episodes

    # Plot results
    plt.plot(total_rewards, label=f"Epsilon = {epsilon}")

plt.xlabel("Steps")
plt.ylabel("Average Reward")
plt.title("Exploitation vs Exploration")
plt.legend()
plt.show()
